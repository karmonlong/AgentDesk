"""
LangGraph æ–‡æ¡£å¤„ç†å·¥ä½œæµ
"""

from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from typing import TypedDict, Optional, Any, Dict
from tools.file_tools import read_file, detect_file_type, save_file
from tools.document_tools import get_operation_prompt
from agents.document_agent import create_document_agent
from langchain_core.messages import HumanMessage
import os
import json
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class DocumentState(TypedDict):
    """æ–‡æ¡£å¤„ç†çŠ¶æ€"""
    file_path: str                  # æ–‡ä»¶è·¯å¾„
    original_filename: str          # åŸå§‹æ–‡ä»¶å
    file_type: Optional[str]        # æ–‡ä»¶ç±»å‹
    content: Optional[str]          # è¯»å–çš„æ–‡ä»¶å†…å®¹
    operation: str                  # æ“ä½œç±»å‹: summarize | generate | convert | extract_table
    instruction: Optional[str]      # ç”¨æˆ·çš„é¢å¤–æŒ‡ä»¤
    extracted_text: Optional[str]   # æå–çš„æ–‡æœ¬å†…å®¹
    result: Optional[str]           # AIå¤„ç†ç»“æœ
    needs_review: bool              # æ˜¯å¦éœ€è¦äººå·¥å®¡æ ¸
    review_approved: Optional[bool]# å®¡æ ¸ç»“æœ
    error: Optional[str]            # é”™è¯¯ä¿¡æ¯
    metadata: Optional[Dict[str, Any]]  # å…ƒæ•°æ®


def node_read_file(state: DocumentState) -> DocumentState:
    """è¯»å–æ–‡ä»¶èŠ‚ç‚¹"""
    print(f"\nğŸ“„ æ­£åœ¨è¯»å–æ–‡ä»¶: {state['original_filename']}")

    try:
        # æ£€æµ‹æ–‡ä»¶ç±»å‹
        file_type = detect_file_type(state['file_path'])
        state['file_type'] = file_type
        print(f"   æ£€æµ‹åˆ°çš„æ–‡ä»¶ç±»å‹: {file_type}")

        # è¯»å–æ–‡ä»¶å†…å®¹
        content = read_file(state['file_path'], file_type)
        state['content'] = content
        state['extracted_text'] = content[:2000]  # å‰2000å­—ç”¨äºAIå¤„ç†

        print(f"âœ… æ–‡ä»¶è¯»å–æˆåŠŸï¼Œå…± {len(content)} å­—ç¬¦")

    except Exception as e:
        state['error'] = f"è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}"
        print(f"âŒ {state['error']}")

    return state


def node_validate_file(state: DocumentState) -> DocumentState:
    """éªŒè¯æ–‡ä»¶èŠ‚ç‚¹"""
    if state.get('error'):
        return state

    if not state.get('content'):
        state['error'] = "æ–‡ä»¶å†…å®¹ä¸ºç©º"

    return state


def node_process_with_agent(state: DocumentState) -> DocumentState:
    """è°ƒç”¨AIæ™ºèƒ½ä½“å¤„ç†èŠ‚ç‚¹"""
    if state.get('error'):
        return state

    print(f"\nğŸ¤– æ­£åœ¨è°ƒç”¨AIæ™ºèƒ½ä½“è¿›è¡Œ: {state['operation']}")

    try:
        # åˆ›å»ºæç¤ºè¯
        prompt = get_operation_prompt(
            operation=state['operation'],
            content=state['extracted_text'][:4000],  # é™åˆ¶token
            instruction=state.get('instruction', '')
        )

        print(f"   æç¤ºè¯é¢„è§ˆ: {prompt[:100]}...")

        # è°ƒç”¨æ™ºèƒ½ä½“
        agent = create_document_agent()
        print(f"   DEBUG: Agentç±»å‹ = {type(agent)}")
        print(f"   DEBUG: Agentæœ‰invokeå±æ€§ = {hasattr(agent, 'invoke')}")

        # è°ƒç”¨æ™ºèƒ½ä½“
        result = agent.invoke({"messages": [HumanMessage(content=prompt)]})

        print(f"   DEBUG: Resultç±»å‹ = {type(result)}")
        print(f"   DEBUG: Resultå€¼ = {str(result)[:200]}...")

        # æå–AIå“åº”å†…å®¹
        ai_response = result.content if hasattr(result, 'content') else str(result)

        print(f"   DEBUG: ai_responseç±»å‹ = {type(ai_response)}")
        print(f"   DEBUG: ai_responseé•¿åº¦ = {len(ai_response) if ai_response else 0}")
        print(f"   DEBUG: ai_responseå‰100å­— = {str(ai_response)[:100]}...")

        # è®¾ç½®ç»“æœ
        state['result'] = ai_response

        print(f"âœ… AIå¤„ç†å®Œæˆï¼Œç»“æœé•¿åº¦: {len(ai_response) if ai_response else 0} å­—ç¬¦")

        # åˆ¤æ–­æ˜¯å¦éœ€è¦å®¡æ ¸ï¼ˆç»“æœè¾ƒé•¿æˆ–éœ€è¦äººå·¥ç¡®è®¤çš„æ“ä½œï¼‰
        needs_review_criteria = [
            len(ai_response) > 3000,  # ç»“æœå¾ˆé•¿
            state['operation'] == 'generate',  # ç”Ÿæˆå†…å®¹
            '---CONFIDENCE_LOW---' in ai_response  # AIæ ‡è®°ç½®ä¿¡åº¦ä½
        ]

        state['needs_review'] = any(needs_review_criteria)

        if state['needs_review']:
            print("   âš ï¸  ç»“æœéœ€è¦äººå·¥å®¡æ ¸")

    except Exception as e:
        import traceback
        state['error'] = f"AIå¤„ç†å¤±è´¥: {str(e)}"
        print(f"âŒ {state['error']}")
        print(f"   é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

    return state


def node_human_review(state: DocumentState) -> DocumentState:
    """äººå·¥å®¡æ ¸èŠ‚ç‚¹ - æš‚åœç­‰å¾…äººå·¥å†³ç­–"""
    if state.get('error'):
        return state

    print(f"\nğŸ‘€ ç­‰å¾…äººå·¥å®¡æ ¸...")
    print(f"   æ“ä½œ: {state['operation']}")
    print(f"   æ–‡ä»¶å: {state['original_filename']}")
    print(f"   ç»“æœé¢„è§ˆ: {state['result'][:200]}...")

    # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šæš‚åœå¹¶ç­‰å¾…å¤–éƒ¨å®¡æ‰¹
    # å®¡æ‰¹é€šè¿‡åä¼šè®¾ç½® state['review_approved'] = True

    return state


def node_save_result(state: DocumentState) -> DocumentState:
    """ä¿å­˜ç»“æœèŠ‚ç‚¹"""
    if state.get('error'):
        return state

    try:
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        output_filename = f"{os.path.splitext(state['original_filename'])[0]}_{state['operation']}_result.txt"
        output_path = os.path.join('uploads', output_filename)

        # ä¿å­˜å¤„ç†ç»“æœ
        save_file(output_path, state['result'])

        # ä¿å­˜å…ƒæ•°æ®
        metadata = {
            'original_file': state['original_filename'],
            'operation': state['operation'],
            'file_type': state['file_type'],
            'output_file': output_filename,
            'result_length': len(state['result']),
            'reviewed': state.get('review_approved', False)
        }

        metadata_path = output_path + '.metadata.json'
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)

        state['metadata'] = metadata

        print(f"\nâœ… å¤„ç†å®Œæˆï¼")
        print(f"   ç»“æœå·²ä¿å­˜è‡³: {output_path}")
        print(f"   å…ƒæ•°æ®å·²ä¿å­˜è‡³: {metadata_path}")

    except Exception as e:
        state['error'] = f"ä¿å­˜ç»“æœå¤±è´¥: {str(e)}"
        print(f"âŒ {state['error']}")

    return state


def node_error_handler(state: DocumentState) -> DocumentState:
    """é”™è¯¯å¤„ç†èŠ‚ç‚¹"""
    if state.get('error'):
        error_output = f"""
å¤„ç†å¤±è´¥æŠ¥å‘Š
================
é”™è¯¯: {state['error']}
æ–‡ä»¶å: {state['original_filename']}
æ“ä½œ: {state['operation']}

å»ºè®®æ“ä½œ:
1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¯è¯»
2. ç¡®è®¤æ–‡ä»¶æ ¼å¼å—æ”¯æŒ
3. æ£€æŸ¥ OpenAI API å¯†é’¥æ˜¯å¦é…ç½®æ­£ç¡®
4. æŸ¥çœ‹æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯
        """

        error_path = os.path.join('uploads', f"{os.path.splitext(state['original_filename'])[0]}_error.txt")
        save_file(error_path, error_output)

        print(f"\nâŒ å¤„ç†å¤±è´¥ï¼Œé”™è¯¯æŠ¥å‘Šå·²ä¿å­˜è‡³: {error_path}")

    return state


# å®šä¹‰æ¡ä»¶å‡½æ•°
def should_review(state: DocumentState) -> str:
    """åˆ¤æ–­æ˜¯å¦éœ€è¦äººå·¥å®¡æ ¸"""
    if state.get('error'):
        return "error_handler"
    if state['needs_review']:
        return "human_review"
    return "save_result"


def should_continue_after_review(state: DocumentState) -> str:
    """å®¡æ ¸ååˆ¤æ–­æ˜¯å¦ç»§ç»­"""
    if state.get('review_approved'):
        return "save_result"
    else:
        state['error'] = "äººå·¥å®¡æ ¸æœªé€šè¿‡"
        return "error_handler"


# åˆ›å»ºå·¥ä½œæµ
workflow = StateGraph(DocumentState)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("read_file", node_read_file)
workflow.add_node("validate", node_validate_file)
workflow.add_node("process", node_process_with_agent)
workflow.add_node("human_review", node_human_review)
workflow.add_node("save_result", node_save_result)
workflow.add_node("error_handler", node_error_handler)

# å®šä¹‰è¾¹
workflow.set_entry_point("read_file")
workflow.add_edge("read_file", "validate")
workflow.add_edge("validate", "process")

# æ¡ä»¶è¾¹: æ ¹æ®æ˜¯å¦éœ€è¦å®¡æ ¸è¿›è¡Œåˆ†æ”¯
workflow.add_conditional_edges(
    "process",
    should_review,
    {
        "human_review": "human_review",
        "save_result": "save_result",
        "error_handler": "error_handler"
    }
)

# äººå·¥å®¡æ ¸åçš„æ¡ä»¶è¾¹
workflow.add_conditional_edges(
    "human_review",
    should_continue_after_review,
    {
        "save_result": "save_result",
        "error_handler": "error_handler"
    }
)

# é”™è¯¯å¤„ç† -> ç»“æŸ
workflow.add_edge("error_handler", END)

# ä¿å­˜ç»“æœ -> ç»“æŸ
workflow.add_edge("save_result", END)

# ç¼–è¯‘å›¾ï¼ˆæ·»åŠ æŒä¹…åŒ–ï¼‰
memory = MemorySaver()
graph = workflow.compile(checkpointer=memory)


def process_document(
    file_path: str,
    operation: str = "summarize",
    instruction: str = "",
    original_filename: str = None
) -> DocumentState:
    """
    å¤„ç†æ–‡æ¡£çš„å¿«æ·å‡½æ•°

    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        operation: æ“ä½œç±»å‹: summarize/generate/convert/extract_table
        instruction: ç”¨æˆ·çš„é¢å¤–æŒ‡ç¤º
        original_filename: åŸå§‹æ–‡ä»¶å

    Returns:
        å¤„ç†åçš„çŠ¶æ€
    """
    if original_filename is None:
        original_filename = os.path.basename(file_path)

    # åˆ›å»ºåˆå§‹çŠ¶æ€
    initial_state = DocumentState(
        file_path=file_path,
        original_filename=original_filename,
        operation=operation,
        instruction=instruction,
        file_type=None,
        content=None,
        extracted_text=None,
        result=None,
        needs_review=False,
        review_approved=None,
        error=None,
        metadata=None
    )

    print("=" * 60)
    print(f"å¼€å§‹å¤„ç†æ–‡æ¡£: {original_filename}")
    print(f"æ“ä½œç±»å‹: {operation}")
    print("=" * 60)

    # æ‰§è¡Œå·¥ä½œæµ
    config = {"configurable": {"thread_id": "1"}}
    result = graph.invoke(initial_state, config=config)

    print("=" * 60)
    if result.get('error'):
        print(f"âŒ å¤„ç†å¤±è´¥: {result['error']}")
    else:
        print("âœ… å¤„ç†å®Œæˆ")
        if result.get('metadata'):
            output_file = result['metadata'].get('output_file')
            print(f"   ç»“æœæ–‡ä»¶: {output_file}")
    print("=" * 60)

    return result


# å¯¼å‡ºä¸»è¦å‡½æ•°ä¾›å¤–éƒ¨ä½¿ç”¨
__all__ = ["graph", "process_document", "DocumentState"]
